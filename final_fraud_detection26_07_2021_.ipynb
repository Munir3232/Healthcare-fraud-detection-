{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final 2  fraud detection26_07_2021 .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBaYCiJWZQdc"
      },
      "source": [
        "#!pip install -U scikit-learn"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2q2-PIwxKp-T"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split,KFold,StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression ,SGDClassifier\n",
        "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model  import LogisticRegression\n",
        "from sklearn.model_selection  import RandomizedSearchCV,StratifiedKFold\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "\n",
        "from joblib import dump,load\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "sns.set_style('darkgrid')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xyKP7tif0cV"
      },
      "source": [
        "## Function for predicting provider is fraud or not ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUr9m88ZPX6L"
      },
      "source": [
        "def PredictionFunc(Provider):\n",
        "  '''takes provider and returns the predictions 'Y'.'''\n",
        "\n",
        "  # reading all files\n",
        "  #df_provider=pd.read_csv(X[0])\n",
        "  df_benefeciary=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/HEALTHCARE PROVIDER FRAUD DETECTION ANALYSIS/Train_Beneficiarydata-1542865627584.csv')\n",
        "  df_inpatient=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/HEALTHCARE PROVIDER FRAUD DETECTION ANALYSIS/Train_Inpatientdata-1542865627584.csv')\n",
        "  df_outpatient=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/HEALTHCARE PROVIDER FRAUD DETECTION ANALYSIS/Train_Outpatientdata-1542865627584.csv')\n",
        "  print(\"\\nReaded all csv's.\")\n",
        "  \n",
        "  dfInpatientProvider=df_inpatient[df_inpatient['Provider']==Provider]\n",
        "  dfOutpatientProvider=df_outpatient[df_outpatient['Provider']==Provider]\n",
        "\n",
        "  ## COMBINING df_inpatient AND  df_outpatient \n",
        "  df_patient_data=pd.concat([dfInpatientProvider,dfOutpatientProvider])\n",
        "\n",
        "  #joining df_patient_data and df_beneficiary using BeneID \n",
        "  Train_ProviderWithPatient_data=pd.merge(df_patient_data,df_benefeciary,left_on='BeneID',right_on='BeneID',how='inner')\n",
        "  \n",
        "\n",
        "  ## AGE\n",
        "  # creating a timestamp for date '2009-12-01' to measure the age of live benefeciaries from this date\n",
        "  x = pd.to_datetime('2009-12-01',format='%Y-%m-%d')\n",
        "  #print(type(x))\n",
        "  # creating a series age with all age ewual to zero\n",
        "  Train_ProviderWithPatient_data['Age']=0\n",
        "  # Add Age of Person based on his/her DOD(Date of death ) and DOB (Date of Birth)\n",
        "  Train_ProviderWithPatient_data['DOB'] = pd.to_datetime(Train_ProviderWithPatient_data['DOB'] , format = '%Y-%m-%d')\n",
        "  Train_ProviderWithPatient_data['DOD'] = pd.to_datetime(Train_ProviderWithPatient_data['DOD'],format = '%Y-%m-%d',errors='ignore')\n",
        "  # how to calculate age feauture:- filled age column with age calculated using DOB and DOD for dead benefeciaries and\n",
        "  # for live benefeciary age calculated using date '2009-12-01'.\n",
        "  for i in range(len(Train_ProviderWithPatient_data)):\n",
        "      if type(Train_ProviderWithPatient_data['DOD'].iloc[i])==type(x):\n",
        "        Train_ProviderWithPatient_data['Age'].iloc[i]=round(((Train_ProviderWithPatient_data['DOD'].iloc[i]- Train_ProviderWithPatient_data['DOB'].iloc[i])/365).days)\n",
        "      else:\n",
        "        Train_ProviderWithPatient_data['Age'].iloc[i]=round(((x- Train_ProviderWithPatient_data['DOB'].iloc[i])/365).days)\n",
        "  Train_ProviderWithPatient_data['Age']\n",
        "  print('\\nAdded Age feature.')\n",
        "\n",
        "  \n",
        "  print('\\nshape of Train_ProviderWithPatient_data:',Train_ProviderWithPatient_data.shape)\n",
        "\n",
        "  #0 1 Encoding of RenalDiseaseIndicator\n",
        "  Train_ProviderWithPatient_data['RenalDiseaseIndicator']=Train_ProviderWithPatient_data['RenalDiseaseIndicator'].map({'Y':1,'0':0})\n",
        "\n",
        "  #0 1 Encoding of chronic\n",
        "  # convet 2 to 0 and 1 to 1\n",
        "  Train_ProviderWithPatient_data['ChronicCond_Alzheimer']=Train_ProviderWithPatient_data['ChronicCond_Alzheimer'].map({2:0,1:1})\n",
        "  Train_ProviderWithPatient_data['ChronicCond_Heartfailure']=Train_ProviderWithPatient_data['ChronicCond_Heartfailure'].map({2:0,1:1})\n",
        "  Train_ProviderWithPatient_data['ChronicCond_KidneyDisease']=Train_ProviderWithPatient_data['ChronicCond_KidneyDisease'].map({2:0,1:1})\n",
        "  Train_ProviderWithPatient_data['ChronicCond_Cancer']=Train_ProviderWithPatient_data['ChronicCond_Cancer'].map({2:0,1:1})\n",
        "  Train_ProviderWithPatient_data['ChronicCond_ObstrPulmonary']=Train_ProviderWithPatient_data['ChronicCond_ObstrPulmonary'].map({2:0,1:1})\n",
        "  Train_ProviderWithPatient_data['ChronicCond_Depression']=Train_ProviderWithPatient_data['ChronicCond_Depression'].map({2:0,1:1})\n",
        "  Train_ProviderWithPatient_data['ChronicCond_Diabetes']=Train_ProviderWithPatient_data['ChronicCond_Diabetes'].map({2:0,1:1})\n",
        "  Train_ProviderWithPatient_data['ChronicCond_IschemicHeart']=Train_ProviderWithPatient_data['ChronicCond_IschemicHeart'].map({2:0,1:1})\n",
        "  Train_ProviderWithPatient_data['ChronicCond_Osteoporasis']=Train_ProviderWithPatient_data['ChronicCond_Osteoporasis'].map({2:0,1:1})\n",
        "  Train_ProviderWithPatient_data['ChronicCond_rheumatoidarthritis']=Train_ProviderWithPatient_data['ChronicCond_rheumatoidarthritis'].map({2:0,1:1})\n",
        "  Train_ProviderWithPatient_data['ChronicCond_stroke']=Train_ProviderWithPatient_data['ChronicCond_stroke'].map({2:0,1:1})\n",
        "  print('\\n0 1 Encoding of chronic and RenalDiseaseIndicator features.')\n",
        "\n",
        "  #dividing numerical and categorical featues into two list so further procassing using these two list will be helpful.\n",
        "  ListOfCatFeat=['BeneID','ClaimID', 'AttendingPhysician','OperatingPhysician',\n",
        "  'OtherPhysician','ClmDiagnosisCode_1','ClmDiagnosisCode_2','ClmDiagnosisCode_3',\n",
        "  'ClmDiagnosisCode_4','ClmDiagnosisCode_5','ClmDiagnosisCode_6','ClmDiagnosisCode_7',\n",
        "  'ClmDiagnosisCode_8','ClmDiagnosisCode_9','ClmDiagnosisCode_10','ClmProcedureCode_1',\n",
        "  'ClmProcedureCode_2','ClmProcedureCode_3','ClmProcedureCode_4','ClmAdmitDiagnosisCode',\n",
        "  'ClmAdmitDiagnosisCode','DiagnosisGroupCode','Gender','Race','RenalDiseaseIndicator',\n",
        "  'State','County']\n",
        "\n",
        "  #WhetherDead\n",
        "  #if date of DOD is not present then that patient is dead\n",
        "  Train_ProviderWithPatient_data['WhetherDead']= 0\n",
        "  Train_ProviderWithPatient_data.loc[Train_ProviderWithPatient_data.DOD.notnull(),'WhetherDead']=1\n",
        "  print('\\nAdded WhetherDead feature.')\n",
        "\n",
        "  #physician present or not\n",
        "  #list of feature names+_pr ,these feature tells about physician present or not\n",
        "  list_physician_pr=[i+'_pr' for i in Train_ProviderWithPatient_data.columns if 'Physician' in i]\n",
        "  # fillna with 0 ,means if physicain not present then 0 else 1\n",
        "  Train_ProviderWithPatient_data[list_physician_pr] =np.where(Train_ProviderWithPatient_data[['AttendingPhysician',\n",
        "                                                                                                    'OperatingPhysician', \n",
        "                                                                                                    'OtherPhysician']].isnull(), 0, 1)\n",
        "  print('\\nAdded physician present or not features.')\n",
        "\n",
        "  #function for counting unique values in rows.\n",
        "  def uniq(df):\n",
        "    ''' this function  takes features and count unique values in row and \n",
        "    return the count of uniqe values '''\n",
        "    return ([len(set([i for i in x[pd.notnull(x)]])) for x in df.values])\n",
        "\n",
        "  #one physician could work for several roles for one patient so we need to calculate number of unique physicians per patitent\n",
        "  #Number of physician per patient.\n",
        "  Train_ProviderWithPatient_data['NumberOFPhysicians']=uniq(Train_ProviderWithPatient_data[['AttendingPhysician',\n",
        "                                                                                          'OperatingPhysician', \n",
        "                                                                                          'OtherPhysician']])\n",
        "  print('\\nAdded NumberOFPhysicians feature.')\n",
        "  # feature for count of unique physician\n",
        "  #Train_ProviderWithPatient_data['NumberOFPhysicians']\n",
        "  #print('Train_ProviderWithPatient_data:',Train_ProviderWithPatient_data.shape)\n",
        "\n",
        "  # number of ChronicCond featues\n",
        "  list_ChronicCond=[i for i in Train_ProviderWithPatient_data.columns if 'ChronicCond' in i] # list of chronic_cond features\n",
        "  #print('len(list_ChronicCond):',len(list_ChronicCond))\n",
        "  #add this feature\n",
        "  Train_ProviderWithPatient_data['NumberOFChronic']=Train_ProviderWithPatient_data[list_ChronicCond].sum(axis=1)\n",
        "  print('\\nAdded NumberOFChronic feature.')\n",
        "\n",
        "  #count of dignosis\n",
        "  type_of_feature_for_count='DiagnosisCode'\n",
        "  DignosisCodeFeats=[i for i in Train_ProviderWithPatient_data.columns if type_of_feature_for_count in i]\n",
        "  #for unique dignosis code per patient\n",
        "  Train_ProviderWithPatient_data['uniqclaims']=uniq(Train_ProviderWithPatient_data[DignosisCodeFeats])\n",
        "\n",
        "  #for dignosis_count(count if any code repeated for data point)\n",
        "  df=Train_ProviderWithPatient_data\n",
        "  #list of feature names+_pr ,these feature tells about ClmDiagnosisCode present or not\n",
        "  DignosisCodeFeats_pr=[i+'_pr' for i in df.columns if type_of_feature_for_count in i]\n",
        "  # fillna with 0 ,means if ClmDiagnosisCode not present then 0 else 1\n",
        "  df[DignosisCodeFeats_pr] =np.where(df[DignosisCodeFeats].isnull(), 0, 1)\n",
        "  # empty feature for storing count of ClmDiagnosisCode\n",
        "  df['NumOFClmDiagnosisCode']=0\n",
        "  # adding count of ClmDiagnosisCode\n",
        "  for i in DignosisCodeFeats_pr:\n",
        "    df['NumOFClmDiagnosisCode'] +=df[i]\n",
        "  \n",
        "  #if any Dignosiscode is repeated for a patient(in datapoint) or not, this will be captured by ExtraClaims feature\n",
        "  df['ExtraClaims']=df['NumOFClmDiagnosisCode']-Train_ProviderWithPatient_data['uniqclaims']\n",
        "\n",
        "  print('\\nAdded number of uniq claims and total number of claims for provider')\n",
        "\n",
        "  #Count procedure_count\n",
        "  type_of_feature_for_count='ProcedureCode'\n",
        "  ProcedureCode_feats=[i for i in Train_ProviderWithPatient_data.columns if type_of_feature_for_count in i]\n",
        "  #for unique Procedure codes per patient\n",
        "  Train_ProviderWithPatient_data['UniqProcedures']=uniq(Train_ProviderWithPatient_data[ProcedureCode_feats])\n",
        "  #for ProcedureCode_count\n",
        "\n",
        "  #list of feature names+_pr ,these feature tells about ProcedureCode present or not\n",
        "  ProcedureCodeFeat_pr=[i+'_pr' for i in Train_ProviderWithPatient_data.columns if type_of_feature_for_count in i]\n",
        "  # fillna with 0 ,means if ProcedureCode not present then 0 else 1\n",
        "  Train_ProviderWithPatient_data[ProcedureCodeFeat_pr] =np.where(Train_ProviderWithPatient_data[ProcedureCode_feats].isnull(), 0, 1)\n",
        "  # empty feature for storing count of ProcedureCode\n",
        "  Train_ProviderWithPatient_data['NumOfProcedureCode']=0\n",
        "  # adding count of ProcedureCode\n",
        "  for i in ProcedureCodeFeat_pr:\n",
        "    Train_ProviderWithPatient_data['NumOfProcedureCode'] +=Train_ProviderWithPatient_data[i]\n",
        "\n",
        "  print('\\nAdded number of uniq ProcedureCode and total number of ProcedureCode for provider')\n",
        "\n",
        "  ##DATE TO DAYS CREATED days_to_process_claim,Admit_days FEATURES\n",
        "  # Using admission date and discharge date create feature admit days \n",
        "  Train_ProviderWithPatient_data['AdmissionDt'] = pd.to_datetime(Train_ProviderWithPatient_data['AdmissionDt'] , format = '%Y-%m-%d')\n",
        "  Train_ProviderWithPatient_data['DischargeDt'] = pd.to_datetime(Train_ProviderWithPatient_data['DischargeDt'],format = '%Y-%m-%d',errors='ignore')\n",
        "  Train_ProviderWithPatient_data['Admit_days'] = round(((Train_ProviderWithPatient_data['DischargeDt'] - Train_ProviderWithPatient_data['AdmissionDt']).dt.days))\n",
        "  Train_ProviderWithPatient_data['Admit_days']=Train_ProviderWithPatient_data['Admit_days'].fillna(0)\n",
        "\n",
        "  # Add feature days_to_process_claim which says about how many days are taken to process the claim\n",
        "  # using claimEndDate-ClaimStartDate\n",
        "  Train_ProviderWithPatient_data['ClaimStartDt'] = pd.to_datetime(Train_ProviderWithPatient_data['ClaimStartDt'] , format = '%Y-%m-%d')\n",
        "  Train_ProviderWithPatient_data['ClaimEndDt'] = pd.to_datetime(Train_ProviderWithPatient_data['ClaimEndDt'],format = '%Y-%m-%d',errors='ignore')\n",
        "  Train_ProviderWithPatient_data['DaysToProcessClaim'] = round(((Train_ProviderWithPatient_data['ClaimEndDt'] - Train_ProviderWithPatient_data['ClaimStartDt']).dt.days))\n",
        "\n",
        "  print('\\nAdded Admit_days,DaysToProcessClaim features. ')\n",
        "\n",
        "  #Interaction Features\n",
        "  ##Numerical feature interaction\n",
        "  #Frauds have more deductible amount\n",
        "  #frauda trying to get more InscClaimAmtReimbursed\n",
        "  # interaction of these two will help\n",
        "  Train_ProviderWithPatient_data['InscClaimAmtReimbursedPlusIPAnnualReimbursementAmt']=Train_ProviderWithPatient_data['InscClaimAmtReimbursed']+Train_ProviderWithPatient_data['IPAnnualReimbursementAmt']\n",
        "  Train_ProviderWithPatient_data['InscClaimAmtReimbursedPlusOPAnnualReimbursementAmt']=Train_ProviderWithPatient_data['InscClaimAmtReimbursed']+Train_ProviderWithPatient_data['OPAnnualReimbursementAmt']\n",
        "  Train_ProviderWithPatient_data['IPAnnualReimbursementAmtPlusOPAnnualReimbursementAmt']=Train_ProviderWithPatient_data['IPAnnualReimbursementAmt']+Train_ProviderWithPatient_data['OPAnnualReimbursementAmt']\n",
        "  Train_ProviderWithPatient_data['DeductibleAmtPaidPlusIPAnnualDeductibleAmt']=Train_ProviderWithPatient_data['DeductibleAmtPaid']+Train_ProviderWithPatient_data['IPAnnualDeductibleAmt']\n",
        "  Train_ProviderWithPatient_data['DeductibleAmtPaidPlusOPAnnualDeductibleAmt']=Train_ProviderWithPatient_data['DeductibleAmtPaid']+Train_ProviderWithPatient_data['OPAnnualDeductibleAmt']\n",
        "  Train_ProviderWithPatient_data['IPAnnualDeductibleAmtPlusOPAnnualDeductibleAmt']=Train_ProviderWithPatient_data['IPAnnualDeductibleAmt']+Train_ProviderWithPatient_data['OPAnnualDeductibleAmt']\n",
        "  print('\\nusing feature interacton of numerical features I added 6 features')\n",
        "\n",
        "  ##categorical feature interaction\n",
        "  Train_ProviderWithPatient_data['Provider_BeneID']=Train_ProviderWithPatient_data['Provider']+'_'+Train_ProviderWithPatient_data['BeneID']\n",
        "  Train_ProviderWithPatient_data['Provider_AttendingPhysician']=Train_ProviderWithPatient_data['Provider']+'_'+Train_ProviderWithPatient_data['AttendingPhysician']\n",
        "  Train_ProviderWithPatient_data['BeneID_AttendingPhysician']=Train_ProviderWithPatient_data['BeneID']+'_'+Train_ProviderWithPatient_data['AttendingPhysician']\n",
        "  Train_ProviderWithPatient_data['ClmDiagnosisCode_1_AttendingPhysician']=Train_ProviderWithPatient_data['ClmDiagnosisCode_1']+'_'+Train_ProviderWithPatient_data['AttendingPhysician']\n",
        "  print('\\nusing feature interaction of categorical features I added 4 features')\n",
        "\n",
        "  #DiagnosisGroupCode says about patitient was hospitalixed or not.\n",
        "  Train_ProviderWithPatient_data['1_0DiagnosisGroupCode']=np.where(Train_ProviderWithPatient_data.DiagnosisGroupCode.notnull(), 1, 0)\n",
        "\n",
        "  #Creating new dataframe data which will be used for grouping using provider and finding min,max, sum based features .\n",
        "  data=Train_ProviderWithPatient_data[[ 'Provider','InscClaimAmtReimbursed', \n",
        "       'DeductibleAmtPaid',\n",
        "       'RenalDiseaseIndicator', 'County',\n",
        "       'ChronicCond_Alzheimer',\n",
        "       'ChronicCond_Heartfailure', 'ChronicCond_KidneyDisease',\n",
        "       'ChronicCond_Cancer', 'ChronicCond_ObstrPulmonary',\n",
        "       'ChronicCond_Depression', 'ChronicCond_Diabetes',\n",
        "       'ChronicCond_IschemicHeart', 'ChronicCond_Osteoporasis',\n",
        "       'ChronicCond_rheumatoidarthritis', 'ChronicCond_stroke',\n",
        "       'IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt',\n",
        "       'OPAnnualReimbursementAmt', 'OPAnnualDeductibleAmt', 'Age',\n",
        "       'WhetherDead', 'NumberOFPhysicians','NumberOFChronic', 'uniqclaims', \n",
        "       'NumOFClmDiagnosisCode', 'ExtraClaims', 'UniqProcedures',\n",
        "       'NumOfProcedureCode',\n",
        "       'Admit_days', 'DaysToProcessClaim', '1_0DiagnosisGroupCode',\n",
        "       'InscClaimAmtReimbursedPlusIPAnnualReimbursementAmt',\n",
        "       'InscClaimAmtReimbursedPlusOPAnnualReimbursementAmt',\n",
        "       'IPAnnualReimbursementAmtPlusOPAnnualReimbursementAmt',\n",
        "       'DeductibleAmtPaidPlusIPAnnualDeductibleAmt',\n",
        "       'DeductibleAmtPaidPlusOPAnnualDeductibleAmt',\n",
        "       'IPAnnualDeductibleAmtPlusOPAnnualDeductibleAmt',\n",
        "       \n",
        "       ]]\n",
        "  #fill na with 0\n",
        "  data=data.fillna(0)\n",
        "\n",
        "  df1=data.groupby(['Provider'], as_index = False)[[ 'Provider','InscClaimAmtReimbursed', \n",
        "       'DeductibleAmtPaid',\n",
        "       'RenalDiseaseIndicator', 'County',\n",
        "       'ChronicCond_Alzheimer',\n",
        "       'ChronicCond_Heartfailure', 'ChronicCond_KidneyDisease',\n",
        "       'ChronicCond_Cancer', 'ChronicCond_ObstrPulmonary',\n",
        "       'ChronicCond_Depression', 'ChronicCond_Diabetes',\n",
        "       'ChronicCond_IschemicHeart', 'ChronicCond_Osteoporasis',\n",
        "       'ChronicCond_rheumatoidarthritis', 'ChronicCond_stroke',\n",
        "       'IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt',\n",
        "       'OPAnnualReimbursementAmt', 'OPAnnualDeductibleAmt', 'Age',\n",
        "       'WhetherDead', 'NumberOFPhysicians','NumberOFChronic', 'uniqclaims', \n",
        "       'NumOFClmDiagnosisCode', 'ExtraClaims', 'UniqProcedures',\n",
        "       'NumOfProcedureCode',\n",
        "       'Admit_days', 'DaysToProcessClaim', '1_0DiagnosisGroupCode',\n",
        "       'InscClaimAmtReimbursedPlusIPAnnualReimbursementAmt',\n",
        "       'InscClaimAmtReimbursedPlusOPAnnualReimbursementAmt',\n",
        "       'IPAnnualReimbursementAmtPlusOPAnnualReimbursementAmt',\n",
        "       'DeductibleAmtPaidPlusIPAnnualDeductibleAmt',\n",
        "       'DeductibleAmtPaidPlusOPAnnualDeductibleAmt',\n",
        "       'IPAnnualDeductibleAmtPlusOPAnnualDeductibleAmt']].sum()\n",
        "  print('\\nshape of df using sum of values:',df1.shape)\n",
        "\n",
        "  DfMaxMoney=data.groupby(['Provider'], as_index = False)[[ 'Provider','InscClaimAmtReimbursed', \n",
        "       'DeductibleAmtPaid',\n",
        "       'RenalDiseaseIndicator', 'County',\n",
        "       'ChronicCond_Alzheimer',\n",
        "       'ChronicCond_Heartfailure', 'ChronicCond_KidneyDisease',\n",
        "       'ChronicCond_Cancer', 'ChronicCond_ObstrPulmonary',\n",
        "       'ChronicCond_Depression', 'ChronicCond_Diabetes',\n",
        "       'ChronicCond_IschemicHeart', 'ChronicCond_Osteoporasis',\n",
        "       'ChronicCond_rheumatoidarthritis', 'ChronicCond_stroke',\n",
        "       'IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt',\n",
        "       'OPAnnualReimbursementAmt', 'OPAnnualDeductibleAmt', 'Age',\n",
        "       'WhetherDead', 'NumberOFPhysicians','NumberOFChronic', 'uniqclaims', \n",
        "       'NumOFClmDiagnosisCode', 'ExtraClaims', 'UniqProcedures',\n",
        "       'NumOfProcedureCode',\n",
        "       'Admit_days', 'DaysToProcessClaim', '1_0DiagnosisGroupCode',\n",
        "       'InscClaimAmtReimbursedPlusIPAnnualReimbursementAmt',\n",
        "       'InscClaimAmtReimbursedPlusOPAnnualReimbursementAmt',\n",
        "       'IPAnnualReimbursementAmtPlusOPAnnualReimbursementAmt',\n",
        "       'DeductibleAmtPaidPlusIPAnnualDeductibleAmt',\n",
        "       'DeductibleAmtPaidPlusOPAnnualDeductibleAmt',\n",
        "       'IPAnnualDeductibleAmtPlusOPAnnualDeductibleAmt']].max()\n",
        "  print('\\nshape of df using max values:',DfMaxMoney.shape)\n",
        "\n",
        "  # beneID will be number of unique beneID's for a provider and \n",
        "  # ClaimID will be number of unique ClaimID's for a provider \n",
        "  df2 = Train_ProviderWithPatient_data[['BeneID', 'ClaimID']].groupby(Train_ProviderWithPatient_data['Provider']).nunique().reset_index()\n",
        "  #df2 will contain above two features\n",
        "\n",
        "  # Calculate mean features df\n",
        "  df3 = data.groupby(['Provider'], as_index = False)[['IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt',\n",
        "                                                      'OPAnnualReimbursementAmt', 'OPAnnualDeductibleAmt', 'Age',\n",
        "                                                      'InscClaimAmtReimbursedPlusIPAnnualReimbursementAmt',\n",
        "                                                      'InscClaimAmtReimbursedPlusOPAnnualReimbursementAmt',\n",
        "                                                      'IPAnnualReimbursementAmtPlusOPAnnualReimbursementAmt',\n",
        "                                                      'DeductibleAmtPaidPlusIPAnnualDeductibleAmt',\n",
        "                                                      'DeductibleAmtPaidPlusOPAnnualDeductibleAmt',\n",
        "                                                      'IPAnnualDeductibleAmtPlusOPAnnualDeductibleAmt']].mean()\n",
        "  print('\\nshape of df using mean of money features:',df3.shape)\n",
        "  #conveting column names to feature_name+mean\n",
        "  df3.columns=['Provider']+[i+'Mean' for i in ['IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt',\n",
        "  'OPAnnualReimbursementAmt', 'OPAnnualDeductibleAmt', 'Age',\n",
        "  'InscClaimAmtReimbursedPlusIPAnnualReimbursementAmt',\n",
        "  'InscClaimAmtReimbursedPlusOPAnnualReimbursementAmt',\n",
        "  'IPAnnualReimbursementAmtPlusOPAnnualReimbursementAmt',\n",
        "  'DeductibleAmtPaidPlusIPAnnualDeductibleAmt',\n",
        "  'DeductibleAmtPaidPlusOPAnnualDeductibleAmt',\n",
        "  'IPAnnualDeductibleAmtPlusOPAnnualDeductibleAmt']]\n",
        "\n",
        "  ### Combine all the different features into single df for modeling\n",
        "  df = df2.merge(df1, on='Provider', how='left').merge(df3, on='Provider', how='left')\\\n",
        "  .merge(DfMaxMoney,on='Provider',how='left')#.merge(CountleastFreqCat_Df,on='Provider',how='left')\n",
        "  print('\\nShape of Df containing combination of all features:',df.shape)\n",
        "  df\n",
        "  \n",
        "  # data\n",
        "  df=df.drop(['Provider'],axis=1)\n",
        "  minmax=load('/content/drive/MyDrive/Colab Notebooks/HEALTHCARE PROVIDER FRAUD DETECTION ANALYSIS/models/MinMaxScaler.joblib')\n",
        "  df=minmax.transform(df)\n",
        "  print('\\nscaling Done')\n",
        "  clf=load('/content/drive/MyDrive/Colab Notebooks/HEALTHCARE PROVIDER FRAUD DETECTION ANALYSIS/models/DecisionTreeClassifier.joblib')\n",
        "  prediction=clf.predict(df)\n",
        "  print('\\nPredictions Done')\n",
        "  list_of_Labels=['Not Fraud','Fraud']\n",
        "  #print(\"\\nProvider '{}' is {}.\".format(Provider,list_of_Labels[prediction[0]]))\n",
        "\n",
        "  return list_of_Labels[prediction[0]]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq1tEw2tfpvz"
      },
      "source": [
        "##Making prediction for random provider from dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8u6nOxgGa9y0",
        "outputId": "b4cf87b5-bca7-454d-9ec9-54cdf189b92a"
      },
      "source": [
        "# picking a random provider from provider data Provider='PRV51001'\n",
        "Provider='PRV51001'\n",
        "\n",
        "Y=PredictionFunc(Provider)   # predicting provider is fraud or not \n",
        "\n",
        "print('\\n------------------------------------------------------------------- -: Result :- -----------------------------------------------------------')\n",
        "print(\"\\nProvider '{}' is {}.\".format(Provider,Y))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Readed all csv's.\n",
            "\n",
            "Added Age feature.\n",
            "\n",
            "shape of Train_ProviderWithPatient_data: (25, 55)\n",
            "\n",
            "0 1 Encoding of chronic and RenalDiseaseIndicator features.\n",
            "\n",
            "Added WhetherDead feature.\n",
            "\n",
            "Added physician present or not features.\n",
            "\n",
            "Added NumberOFPhysicians feature.\n",
            "\n",
            "Added NumberOFChronic feature.\n",
            "\n",
            "Added number of uniq claims and total number of claims for provider\n",
            "\n",
            "Added number of uniq ProcedureCode and total number of ProcedureCode for provider\n",
            "\n",
            "Added Admit_days,DaysToProcessClaim features. \n",
            "\n",
            "using feature interacton of numerical features I added 6 features\n",
            "\n",
            "using feature interaction of categorical features I added 4 features\n",
            "\n",
            "shape of df using sum of values: (1, 38)\n",
            "\n",
            "shape of df using max values: (1, 38)\n",
            "\n",
            "shape of df using mean of money features: (1, 12)\n",
            "\n",
            "Shape of Df containing combination of all features: (1, 88)\n",
            "\n",
            "scaling Done\n",
            "\n",
            "Predictions Done\n",
            "\n",
            "------------------------------------------------------------------- -: Result :- -----------------------------------------------------------\n",
            "\n",
            "Provider 'PRV51001' is Not Fraud.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBsSgWn5fwbD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
